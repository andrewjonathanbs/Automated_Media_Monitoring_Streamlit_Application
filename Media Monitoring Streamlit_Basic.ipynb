{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bc4b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from requests_html import HTMLSession\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b66c6918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e8260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query = Christophe Pinagiol\n",
      "https://www.fashion-spider.com/natura-brasil-petit-coin-damazonie-rive-droite.fashion\n"
     ]
    }
   ],
   "source": [
    "keywords = ['Christophe Pinagiol', 'APL Healthcare', 'APL Sustainability']\n",
    "\n",
    "def summarizer(url):\n",
    "    # Number of sentences in the summary\n",
    "    num_sentences = 3\n",
    "\n",
    "    # Initialize the parser and tokenizer\n",
    "    parser = HtmlParser.from_url(url, Tokenizer(\"english\"))\n",
    "\n",
    "    # Initialize the summarizer (LexRank algorithm)\n",
    "    summarizer = LexRankSummarizer()\n",
    "\n",
    "    # Summarize the article\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "\n",
    "    # Print the summary\n",
    "    for sentence in summary:\n",
    "        print(sentence)\n",
    "\n",
    "for x in keywords:\n",
    "    Query = x\n",
    "    Limit = int(100)\n",
    "\n",
    "    file = open('Results.txt', 'w')\n",
    "\n",
    "    s = HTMLSession()\n",
    "\n",
    "    headers = {\n",
    "        'authority': 'www.google.com',\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',\n",
    "        'accept-language': 'en-US,en;q=0.5',\n",
    "        'sec-fetch-dest': 'document',\n",
    "        'sec-fetch-mode': 'navigate',\n",
    "        'sec-fetch-site': 'none',\n",
    "        'sec-fetch-user': '?1',\n",
    "        'sec-gpc': '1',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36',\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'q': Query,\n",
    "        'num': Limit,\n",
    "        'tbs': 'qdr:d'\n",
    "    }\n",
    "\n",
    "    response = s.get('https://www.google.com/search', params=params)\n",
    "\n",
    "    if 'did not match any documents' in response.text:\n",
    "        exit('No Results Found')\n",
    "    elif 'Our systems have detected unusual traffic from your computer' in response.text:\n",
    "        exit('Captcha Triggered!\\nUse Vpn Or Try After Sometime.')\n",
    "    else:\n",
    "        links_list = []\n",
    "        links = list(response.html.absolute_links)\n",
    "        for url in links:\n",
    "            if 'google' not in url:\n",
    "                links_list.append(url)\n",
    "                file.write(url + '\\n')\n",
    "    print('Query = ' + Query)\n",
    "    for x in links_list:\n",
    "        print(x)\n",
    "        try:\n",
    "            summary = summarizer(x)\n",
    "            # Use the summary as needed\n",
    "        except Exception as e:\n",
    "            print('Error occurred:', str(e))\n",
    "            print('Unavailable summary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
